{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Import all the packages\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ],
   "metadata": {
    "id": "s3gL3LFHAed8",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:27.603357Z",
     "start_time": "2025-02-15T22:59:25.077674Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:27.679865Z",
     "start_time": "2025-02-15T22:59:27.608403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the device we are using is GPU or CPU\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# Build one of the main components - DoubleConv - for UNet\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ],
   "metadata": {
    "id": "OQospNIGB9CM",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:27.784795Z",
     "start_time": "2025-02-15T22:59:27.780731Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Build UNet from scrach\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        \n",
    "        # Encoder (downsampling path)\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        \n",
    "        # Decoder (upsampling path)\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature * 2, feature))\n",
    "        \n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "\n",
    "        # Encoder forward pass\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections.reverse()\n",
    "\n",
    "        # Decoder forward pass\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            x = self.ups[i](x)  # Upsample\n",
    "            skip_connection = skip_connections[i // 2]  # Get corresponding skip connection\n",
    "            concat = torch.cat((skip_connection, x), dim=1)  # Concatenate along channel dimension\n",
    "            x = self.ups[i + 1](concat)  # Apply double convolution\n",
    "\n",
    "        return self.final_conv(x)\n"
   ],
   "metadata": {
    "id": "rZSFGD-sCHtV",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:27.794324Z",
     "start_time": "2025-02-15T22:59:27.788995Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Create an UNet model object\n",
    "model = UNet()\n",
    "\n",
    "toy_data = torch.ones((16, 3, 240, 160))\n",
    "output = model(toy_data)\n",
    "print(output.shape)\n",
    "# Move the model to GPU\n",
    "model = model.cuda()"
   ],
   "metadata": {
    "id": "MO5Xg0pUJbNp",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:30.899568Z",
     "start_time": "2025-02-15T22:59:28.716159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 240, 160])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Build CustomDataset for loading data from Google Drive\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform):\n",
    "        super().__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.image_dir, self.images[index])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[index].replace('.jpg', '_mask.gif'))\n",
    "\n",
    "        image = np.array(Image.open(img_path))\n",
    "        mask = np.array(Image.open(mask_path).convert('L'))\n",
    "\n",
    "        return self.transform(image), self.transform(mask)\n"
   ],
   "metadata": {
    "id": "ILgSgfqFJidq",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:30.919323Z",
     "start_time": "2025-02-15T22:59:30.915792Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Constants for UNet model training process\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "IMG_WIDTH = 240\n",
    "IMG_HEIGHT = 160"
   ],
   "metadata": {
    "id": "sBoa09DRHUtm",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:30.949163Z",
     "start_time": "2025-02-15T22:59:30.947176Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "all_data = CustomDataset(\n",
    "    'small_train',\n",
    "    'small_train_masks',\n",
    "    T.Compose([\n",
    "        T.ToTensor(),  \n",
    "        T.Resize((IMG_HEIGHT, IMG_WIDTH))\n",
    "    ])\n",
    ")\n"
   ],
   "metadata": {
    "id": "rd67NulqHUly",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:30.967343Z",
     "start_time": "2025-02-15T22:59:30.963989Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Split data into train and val\n",
    "train_data, val_data = torch.utils.data.random_split(all_data, [0.7, 0.3])"
   ],
   "metadata": {
    "id": "GwM6Vz5NKtfm",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:30.981604Z",
     "start_time": "2025-02-15T22:59:30.978525Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Create loader for mini-batch gradient descent\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "id": "Gp2ZXGzHLYmt",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:30.997240Z",
     "start_time": "2025-02-15T22:59:30.994048Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# The loss function for bianry classification\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "# Choosing Adam as our optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ],
   "metadata": {
    "id": "jEJ-RbO6UzJP",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:31.011866Z",
     "start_time": "2025-02-15T22:59:31.008565Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, num_epochs, train_loader, optimizer, print_every=30):\n",
    "    for epoch in range(num_epochs):\n",
    "        for count, (x, y) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            x = x.to(torch.device(\"cuda\"))\n",
    "            y = y.to(torch.device(\"cuda\"))\n",
    "            out = model(x)\n",
    "            if count % print_every == 0:\n",
    "                eval(model, val_loader, epoch)\n",
    "            # out = torch.sigmoid(out)\n",
    "            loss = loss_function(out, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ],
   "metadata": {
    "id": "fYS30O-dSl0L",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:31.027945Z",
     "start_time": "2025-02-15T22:59:31.024944Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def eval(model, val_loader, epoch):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_pixels = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out_img = model(x)\n",
    "            probability = torch.sigmoid(out_img)\n",
    "            predictions = probability>0.5\n",
    "            num_correct += (predictions==y).sum()\n",
    "            num_pixels += BATCH_SIZE*IMG_WIDTH*IMG_HEIGHT\n",
    "    print(f'Epoch[{epoch+1}] Acc: {num_correct/num_pixels}')"
   ],
   "metadata": {
    "id": "4weW5Wi8RWMW",
    "ExecuteTime": {
     "end_time": "2025-02-15T22:59:31.046527Z",
     "start_time": "2025-02-15T22:59:31.043527Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "train(model, NUM_EPOCHS, train_loader, optimizer)"
   ],
   "metadata": {
    "id": "8rcL1usEWTHq",
    "ExecuteTime": {
     "end_time": "2025-02-15T23:05:47.889728Z",
     "start_time": "2025-02-15T22:59:31.060414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Acc: 0.778840184211731\n",
      "Epoch[1] Acc: 0.8511271476745605\n",
      "Epoch[1] Acc: 0.8745274543762207\n",
      "Epoch[2] Acc: 0.8657953143119812\n",
      "Epoch[2] Acc: 0.8731623291969299\n",
      "Epoch[2] Acc: 0.8778730034828186\n",
      "Epoch[3] Acc: 0.8778916001319885\n",
      "Epoch[3] Acc: 0.8741675615310669\n",
      "Epoch[3] Acc: 0.8779928684234619\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "iLmSx5eZGq8t"
   }
  }
 ]
}
